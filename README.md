# GP-based Imputation Project

Este projeto implementa um sistema de imputa√ß√£o de dados faltantes usando Programa√ß√£o Gen√©tica (GP) para combinar m√∫ltiplos m√©todos de imputa√ß√£o.

## Estrutura do Projeto

```
pocii/
‚îú‚îÄ‚îÄ config/                    # Arquivos de configura√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ experiment_config.yaml # Configura√ß√£o de experimentos
‚îÇ   ‚îî‚îÄ‚îÄ gp_config.yaml        # Configura√ß√£o do GP
‚îú‚îÄ‚îÄ data/                      # M√≥dulo de dados
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ loaders.py            # Carregamento de datasets
‚îÇ   ‚îî‚îÄ‚îÄ missingness.py        # Gera√ß√£o de dados faltantes (MCAR, MAR, MNAR)
‚îú‚îÄ‚îÄ imputers/                  # Implementa√ß√µes de imputadores
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base.py               # Classe base
‚îÇ   ‚îú‚îÄ‚îÄ simple.py             # Mean, Median, Mode
‚îÇ   ‚îú‚îÄ‚îÄ knn_imputer.py        # KNN
‚îÇ   ‚îú‚îÄ‚îÄ mice_imputer.py       # MICE
‚îÇ   ‚îú‚îÄ‚îÄ missforest_imputer.py # MissForest
‚îÇ   ‚îî‚îÄ‚îÄ svd_imputer.py        # SVD/Matrix Factorization
‚îú‚îÄ‚îÄ gp/                        # M√≥dulo de Programa√ß√£o Gen√©tica
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ operators.py          # Operadores protegidos
‚îÇ   ‚îú‚îÄ‚îÄ primitives.py         # Setup de primitivas DEAP
‚îÇ   ‚îú‚îÄ‚îÄ fitness.py            # Fun√ß√µes de fitness
‚îÇ   ‚îî‚îÄ‚îÄ gp_imputer.py         # Imputador GP principal
‚îú‚îÄ‚îÄ evaluation/                # Avalia√ß√£o e testes
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py            # RMSE, MAE, NRMSE, R¬≤
‚îÇ   ‚îú‚îÄ‚îÄ statistical_tests.py  # Wilcoxon, Friedman, Nemenyi
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py      # Plots e gr√°ficos
‚îú‚îÄ‚îÄ experiments/               # Scripts de experimentos
‚îÇ   ‚îú‚îÄ‚îÄ run_experiments.py    # Script principal
‚îÇ   ‚îî‚îÄ‚îÄ utils.py              # Utilit√°rios
‚îú‚îÄ‚îÄ notebooks/                 # Notebooks Jupyter para an√°lise
‚îú‚îÄ‚îÄ logs/                      # Logs de execu√ß√£o
‚îú‚îÄ‚îÄ results/                   # Resultados dos experimentos
‚îî‚îÄ‚îÄ requirements.txt           # Depend√™ncias

```

## Instala√ß√£o

### 1. Criar ambiente virtual (recomendado)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 2. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

## Uso

### Executar Experimentos

```bash
cd /scratch/giovana.assis/pocii
python experiments/run_experiments.py
```

Com configura√ß√µes customizadas:

```bash
python experiments/run_experiments.py \
    --config config/experiment_config.yaml \
    --gp-config config/gp_config.yaml
```

### Configura√ß√£o

#### Experiment Config (`config/experiment_config.yaml`)

- **Datasets**: Define quais datasets usar (sklearn ou custom)
- **Missingness**: Mecanismos (MCAR, MAR, MNAR), taxas (5%, 10%, 20%, etc.), seeds
- **Imputers**: Quais imputadores habilitar e seus par√¢metros
- **Evaluation**: M√©tricas e testes estat√≠sticos
- **Experiment**: N√∫mero de repeti√ß√µes, paths de sa√≠da
- **Cross-Validation**: Habilitar/desabilitar valida√ß√£o cruzada e n√∫mero de folds

##### Ativando Cross-Validation

No arquivo `config/experiment_config.yaml`:

```yaml
experiment:
  use_cross_validation: true  # Habilita valida√ß√£o cruzada
  n_folds: 5                  # N√∫mero de folds (padr√£o: 5)
```

Com cross-validation habilitada, o dataset √© dividido em `n_folds` partes. Cada fold √© usado como conjunto de teste, e os resultados s√£o agregados (m√©dia e desvio padr√£o) automaticamente.

#### GP Config (`config/gp_config.yaml`)

- **Population**: Tamanho da popula√ß√£o, gera√ß√µes, elitismo
- **Tree**: Profundidade m√°xima, tamanho m√°ximo, m√©todo de inicializa√ß√£o
- **Evolution**: Taxas de crossover/muta√ß√£o, tournament size
- **Functions**: Conjunto de fun√ß√µes (operadores)
- **Terminals**: Conjunto de terminais (constantes, imputadores)
- **Fitness**: M√©trica e penaliza√ß√£o por complexidade

##### Fitness Baseado em Classificador

O GP pode otimizar diretamente para o desempenho de um classificador (F1-score) ao inv√©s de m√©tricas de imputa√ß√£o:

```yaml
fitness:
  metric: "f1_classifier"  # Usa F1-score do classificador como fitness
  parsimony_coefficient: 0.0001
  
  classifier:
    type: "random_forest"  # random_forest, logistic_regression, svm, decision_tree, knn
    params:
      n_estimators: 100
      max_depth: 10
      random_state: 42
  cv_folds: 5  # Cross-validation folds para avaliar o classificador
```

Quando `metric: "f1_classifier"` est√° configurado:
- O GP evolui programas que maximizam o F1-score do classificador especificado
- A imputa√ß√£o √© avaliada treinando o classificador nos dados imputados
- Cross-validation √© usado para avaliar o classificador de forma robusta
- O fitness √© `1 - F1_score` (minimiza√ß√£o)

## Componentes Principais

### 1. Imputadores Base

Todos os imputadores seguem a interface comum (`fit`, `transform`, `fit_transform`):

- **MeanImputer**: Imputa√ß√£o por m√©dia
- **MedianImputer**: Imputa√ß√£o por mediana
- **KNNImputerWrapper**: K-Nearest Neighbors
- **MICEImputerWrapper**: Multivariate Imputation by Chained Equations
- **MissForestImputerWrapper**: Random Forest iterativo
- **SVDImputerWrapper**: Decomposi√ß√£o SVD

### 2. GP Imputer

O `GPImputer` evolui programas (√°rvores) que combinam as sa√≠das dos imputadores base usando:

**Arquitetura**: **Multi-√Årvore Integrada**
- **1 algoritmo GP** √© executado
- Cada indiv√≠duo cont√©m **N √°rvores** (uma por feature)
- Fitness calculado **globalmente** no dataset completo
- **N√ó mais r√°pido** que evolu√ß√µes independentes
- Features **co-evoluem** para otimiza√ß√£o integrada

**Function Set** (protegido contra erros num√©ricos):
- Bin√°rios: `+, -, *, /, min, max, pow`
- Un√°rios: `sqrt, log, exp, abs`
- Tern√°rio: `if-then-else`

**Terminal Set**:
- Sa√≠das dos imputadores base (para a feature espec√≠fica)
- Constantes fixas: `[-10, -1, 0, 1, 2, 10]`
- Constantes ef√™meras: valores aleat√≥rios em `[-10, 10]`

**Fitness**: 
- **M√©tricas de Imputa√ß√£o**: NRMSE, RMSE, MAE (avaliado em todas as features)
- **M√©tricas de Classifica√ß√£o**: F1-score de classificador (avaliado no dataset completo)

### 3. Gera√ß√£o de Missingness

- **MCAR** (Missing Completely At Random): Remo√ß√£o aleat√≥ria uniforme
- **MAR** (Missing At Random): Dependente de outras vari√°veis observadas
- **MNAR** (Missing Not At Random): Dependente do pr√≥prio valor faltante

### 4. Avalia√ß√£o

**M√©tricas**:
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- NRMSE (Normalized RMSE)
- R¬≤ (Coefficient of Determination)

**Testes Estat√≠sticos**:
- Wilcoxon signed-rank (compara√ß√£o pareada)
- Friedman test (compara√ß√£o m√∫ltipla)
- Nemenyi post-hoc test

## Resultados

Os resultados s√£o salvos em `results/experiment_YYYYMMDD_HHMMSS/`:

- `results.pkl`: Resultados completos (pickle)
- `summary.csv`: Resumo em formato tabular
  - Com CV: inclui colunas `*_std` com desvio padr√£o de cada m√©trica
  - Sem CV: apenas valores de cada execu√ß√£o individual
- `statistical_tests.json`: Resultados dos testes estat√≠sticos

### Hist√≥rico de Evolu√ß√£o do GP

Cada execu√ß√£o do GP salva automaticamente o hist√≥rico completo em `results/gp_history/`:

- **Arquivo**: `gp_evolution_YYYYMMDD_HHMMSS.json.gz` (compactado)
- **Conte√∫do**:
  - Fitness de todos os indiv√≠duos em todas as gera√ß√µes
  - Programas (√°rvores) de todos os indiv√≠duos
  - Tamanho das √°rvores
  - Metadados da execu√ß√£o
  - Melhor indiv√≠duo final

**An√°lise do Hist√≥rico**:
```bash
# Analisar hist√≥rico mais recente
python examples/analyze_gp_history.py
```

**Carregar Hist√≥rico Programaticamente**:
```python
from gp import GPImputer

# Carregar hist√≥rico
history = GPImputer.load_evolution_history('results/gp_history/gp_evolution_20251118_120000.json.gz')

# Analisar
analysis = GPImputer.analyze_history('results/gp_history/gp_evolution_20251118_120000.json.gz')

# Acessar dados
print(analysis['convergence'])  # Fitness por gera√ß√£o
print(analysis['diversity'])     # Diversidade por gera√ß√£o
print(analysis['final_best'])    # Melhor indiv√≠duo
```

### Estrutura dos Resultados com Cross-Validation

Quando cross-validation est√° habilitada, os resultados incluem:

```python
{
  'dataset_name': {
    'MCAR': {
      0.1: {  # missing_rate
        42: {  # seed
          'folds': [fold_0_results, fold_1_results, ...],
          'aggregated': {
            'method_name': {
              'metrics': {
                'rmse_mean': 0.123,
                'rmse_std': 0.012,
                'mae_mean': 0.098,
                'mae_std': 0.009,
                ...
              }
            }
          }
        }
      }
    }
  }
}
```

## Exemplos de Uso

### Scripts de Exemplo Completos

Exemplos pr√°ticos dispon√≠veis em `examples/`:

```bash
# Demonstra GP com fitness de classificador
python examples/gp_with_classifier_fitness.py

# Compara fitness de imputa√ß√£o vs. fitness de classificador
python examples/compare_fitness_approaches.py

# Demonstra uma √°rvore GP por feature
python examples/per_feature_trees.py

# Demonstra arquitetura multi-√°rvore
python examples/multitree_demo.py

# Analisa hist√≥rico de evolu√ß√£o do GP
python examples/analyze_gp_history.py
```

Estes scripts demonstram:
- Cria√ß√£o de dados com missing values
- Treinamento de imputadores base
- Uso do GP com diferentes configura√ß√µes de fitness
- Uma √°rvore GP personalizada por feature
- An√°lise completa do hist√≥rico de evolu√ß√£o
- Compara√ß√£o de resultados

---

## üîç Otimiza√ß√£o de Hiperpar√¢metros (Optuna)

### Otimizar Imputadores Automaticamente

```bash
# Executar otimiza√ß√£o com Optuna
python experiments/optuna_optimization.py --config config/optuna_config.yaml

# Analisar resultados
python experiments/analyze_optuna_results.py results/optuna_optimization/all_optimization_results_*.csv
```

**Recursos:**
- ‚úÖ Otimiza√ß√£o autom√°tica de KNN, MICE, MissForest, SVD
- ‚úÖ M√∫ltiplos datasets e n√≠veis de missing values
- ‚úÖ Paraleliza√ß√£o de trials
- ‚úÖ Visualiza√ß√µes interativas (Plotly)
- ‚úÖ Persist√™ncia em SQLite

**Configura√ß√£o r√°pida:**

```yaml
# config/optuna_config.yaml
optuna:
  n_trials: 100
  n_jobs: 4

datasets:
  - name: "breast_cancer"
    type: "sklearn"

imputers:
  knn:
    enabled: true
    params:
      n_neighbors: {type: "int", low: 3, high: 20}
      weights: {type: "categorical", choices: ["uniform", "distance"]}
```

üìñ **Documenta√ß√£o completa:** [docs/OPTUNA_OPTIMIZATION.md](docs/OPTUNA_OPTIMIZATION.md)

### Uso Individual de Imputadores

```python
from imputers import MeanImputer, KNNImputerWrapper
import numpy as np

# Dados com valores faltantes
X = np.array([[1, 2, np.nan],
              [4, np.nan, 6],
              [7, 8, 9]])

# Mean Imputer
mean_imp = MeanImputer()
X_mean = mean_imp.fit_transform(X)

# KNN Imputer
knn_imp = KNNImputerWrapper(n_neighbors=2)
X_knn = knn_imp.fit_transform(X)
```

### Uso do GP Imputer

#### Modo 1: Fitness baseado em m√©tricas de imputa√ß√£o

```python
from gp import GPImputer
from imputers import MeanImputer, MedianImputer

# Preparar base imputers
base_imputers = {
    'imp_mean': MeanImputer().fit(X),
    'imp_median': MedianImputer().fit(X)
}

# GP config
gp_config = {
    'population': {'size': 100, 'generations': 30},
    'tree': {'max_depth': 5},
    'fitness': {'metric': 'rmse', 'parsimony_coefficient': 0.001}
}

# Criar e treinar GP
gp_imp = GPImputer(config=gp_config)
gp_imp.fit(X, base_imputers, y_true=X_complete[missing_mask])

# Imputar
X_gp = gp_imp.transform(X)

# Ver melhor programa
print(gp_imp.get_best_program())
```

#### Modo 2: Fitness baseado em classificador (F1-score)

```python
from gp import GPImputer
from imputers import MeanImputer, MedianImputer, KNNImputerWrapper
from sklearn.ensemble import RandomForestClassifier

# Preparar base imputers
base_imputers = {
    'imp_mean': MeanImputer().fit(X),
    'imp_median': MedianImputer().fit(X),
    'imp_knn': KNNImputerWrapper(n_neighbors=5).fit(X)
}

# GP config com fitness de classificador
gp_config = {
    'population': {'size': 100, 'generations': 30},
    'tree': {'max_depth': 5},
    'fitness': {
        'metric': 'f1_classifier',
        'classifier': {
            'type': 'random_forest',
            'params': {'n_estimators': 100, 'random_state': 42}
        },
        'cv_folds': 5
    }
}

# Criar classificador
classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Criar e treinar GP (precisa de y_target para classifica√ß√£o)
gp_imp = GPImputer(config=gp_config)
gp_imp.fit(X, base_imputers, classifier=classifier, y_target=y_labels)

# Imputar
X_gp = gp_imp.transform(X)

# Ver melhores programas
programs = gp_imp.get_best_program()
print(f"Evolved {len(programs)} GP trees, one per feature")
for feat_name, prog in list(programs.items())[:3]:  # Show first 3
    print(f"{feat_name}: {prog}")
print(f"Best fitness (1 - F1): {gp_imp.best_fitness_:.4f}")
```

### Gerar Dados Faltantes

```python
from data import generate_missing_data

X_complete = np.random.rand(100, 10)

# MCAR
X_mcar, mask_mcar = generate_missing_data(X_complete, 'MCAR', 0.2, seed=42)

# MAR
X_mar, mask_mar = generate_missing_data(X_complete, 'MAR', 0.2, seed=42,
                                       dependency_col=0)

# MNAR
X_mnar, mask_mnar = generate_missing_data(X_complete, 'MNAR', 0.2, seed=42)
```

## Extens√µes Futuras

- [ ] Suporte para dados categ√≥ricos
- [ ] Otimiza√ß√£o de hiperpar√¢metros dos base imputers
- [ ] Ensemble de m√∫ltiplos programas GP
- [ ] Visualiza√ß√µes interativas (Plotly Dash)
- [ ] Paraleliza√ß√£o distribu√≠da (Dask, Ray)
- [x] ‚úÖ Cross-validation integrada
- [x] ‚úÖ Fitness baseado em classificador (F1-score)
- [x] ‚úÖ Arquitetura multi-√°rvore integrada (1 GP, N √°rvores por indiv√≠duo)

## Documenta√ß√£o Adicional

- **[Guia de Fitness de Classificador](docs/CLASSIFIER_FITNESS_GUIDE.md)**: Documenta√ß√£o completa sobre fitness baseado em classificador
- **[Arquitetura Multi-√Årvore](docs/MULTITREE_ARCHITECTURE.md)**: Explica√ß√£o detalhada da arquitetura multi-√°rvore integrada
- **Exemplos pr√°ticos**:
  - `examples/gp_with_classifier_fitness.py`: Uso b√°sico do GP com classificador
  - `examples/compare_fitness_approaches.py`: Compara√ß√£o entre abordagens de fitness
  - `examples/per_feature_trees.py`: Demonstra√ß√£o de √°rvores personalizadas por feature

## Refer√™ncias

- DEAP: Distributed Evolutionary Algorithms in Python
- Scikit-learn: Machine Learning in Python
- Programa√ß√£o Gen√©tica para imputa√ß√£o de dados

## Licen√ßa

MIT License

## Autores

Projeto desenvolvido para pesquisa em imputa√ß√£o de dados usando Programa√ß√£o Gen√©tica.
